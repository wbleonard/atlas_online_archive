{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Online Archive\n",
    "\n",
    "[Atlas Online Archive](https://docs.atlas.mongodb.com/online-archive/manage-online-archive/) moves infrequently accessed immutable data from your Atlas cluster to MongoDB-managed read-only blob storage without user action. Once Atlas archives the data, you have a unified view of your Atlas and Online Archive data.\n",
    "\n",
    "In this demo we will generate 1000 IoT events for the current year. Here's an example event:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "  '_id': ObjectId('5ef4ff46cf35f6a16e7f88a9'),\n",
    "  'username': 'rogerrhodes',\n",
    "  'remote_ipv4': '82.180.218.173',\n",
    "  'httpMethod': 'PATCH',\n",
    "  'hostName': 'desktop-51.freeman.net',\n",
    "  'portNum': 52048,\n",
    "  'location': {\n",
    "    'type': 'Point',\n",
    "    'coordinates': [\n",
    "      Decimal128('-158.511919'),\n",
    "      Decimal128('24.326279')\n",
    "    ]\n",
    "  },\n",
    "  'dateAccessed': datetime.datetime(2020,  6,  15,  0,  0)\n",
    "}\n",
    "```\n",
    "\n",
    "The events will be written to ```test.iot``` and Online Archive has been configured to achive documents whose ```dateAccessed``` field is older than 30 days:\n",
    "\n",
    "<img src=\"./images/online_archive.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import datetime\n",
    "from timeit import default_timer as timer\n",
    "import settings\n",
    "from pymongo import MongoClient\n",
    "from faker import Faker\n",
    "from bson.decimal128 import Decimal128\n",
    "import requests\n",
    "from requests.auth import HTTPDigestAuth\n",
    "import json\n",
    "\n",
    "\n",
    "# Constants loaded from .env file\n",
    "MDB_CONNECTION = settings.MDB_CONNECTION\n",
    "MDB_CONNECTION_ARCHIVE = settings.MDB_CONNECTION_ARCHIVE\n",
    "MDB_DATABASE = settings.MDB_DATABASE\n",
    "MDB_COLLECTION = settings.MDB_COLLECTION\n",
    "NUM_DOCS = settings.NUM_DOCS\n",
    "API_PUBLIC_KEY = settings.API_PUBLIC_KEY\n",
    "API_PRIVATE_KEY = settings.API_PRIVATE_KEY\n",
    "PROJECT_ID = settings.PROJECT_ID\n",
    "CLUSTER_NAME = settings.CLUSTER_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_archive_id():\n",
    "    url = \"https://cloud.mongodb.com/api/atlas/v1.0/groups/\" + PROJECT_ID +\"/clusters/\" + CLUSTER_NAME  +\"/onlineArchives\"\n",
    "    resp = requests.get(url, auth=HTTPDigestAuth(API_PUBLIC_KEY, API_PRIVATE_KEY))\n",
    "\n",
    "    if (resp.ok):\n",
    "\n",
    "        archives = json.loads(resp.content)\n",
    "        #print (\"There are {0} online archive(s)\".format(len(archives)))\n",
    "\n",
    "        for archive in archives:\n",
    "\n",
    "            # There can only be one online archive per collection.\n",
    "            if (archive['dbName'] == MDB_DATABASE and archive['collName'] == MDB_COLLECTION):\n",
    "                return archive['_id']\n",
    "            else:\n",
    "                return 0;\n",
    "        \n",
    "        return 0;\n",
    "\n",
    "    else:\n",
    "        print(resp)\n",
    "        \n",
    "def get_archive_state(id):\n",
    "        \n",
    "    url = \"https://cloud.mongodb.com/api/atlas/v1.0/groups/\" + PROJECT_ID +\"/clusters/\" + CLUSTER_NAME  +\"/onlineArchives/\" + str(id)\n",
    "    resp = requests.get(url, auth=HTTPDigestAuth(API_PUBLIC_KEY, API_PRIVATE_KEY))\n",
    "\n",
    "    if (resp.ok):\n",
    "        return resp.json()['state']\n",
    "\n",
    "    else:\n",
    "        print(resp)\n",
    "        \n",
    "def print_row(count, source):\n",
    "    formatted_count = str(count).rjust(5)\n",
    "    print(\" %-10s %45s\" % (formatted_count, source))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive Creation\n",
    "To keep the archive clean between demos (so there's alsways 1000 documents between the cluster and the archive), the OnLine Archive API is used to re-create the archive before each demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing archive\n"
     ]
    }
   ],
   "source": [
    "## Delete Existing Archive \n",
    "\n",
    "archive_id = get_archive_id()\n",
    "\n",
    "if (archive_id): \n",
    "    \n",
    "    url = \"https://cloud.mongodb.com/api/atlas/v1.0/groups/\" + PROJECT_ID +\"/clusters/\" + CLUSTER_NAME  +\"/onlineArchives/\" + archive_id\n",
    "    resp = requests.delete(url, auth=HTTPDigestAuth(API_PUBLIC_KEY, API_PRIVATE_KEY))\n",
    "\n",
    "    if (resp.ok):\n",
    "        time.sleep(3) # Allowance for deletion to complete\n",
    "        print(\"Deleted existing archive\")  \n",
    "\n",
    "    else:\n",
    "        print(resp)\n",
    "        \n",
    "else:\n",
    "    print(\"No existing archive found for this demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [500]>\n"
     ]
    }
   ],
   "source": [
    "## Create New Archive\n",
    "\n",
    "date_field = \"dateAccessed\"\n",
    "\n",
    "url = \"https://cloud.mongodb.com/api/atlas/v1.0/groups/\" + PROJECT_ID +\"/clusters/\" + CLUSTER_NAME  +\"/onlineArchives\"\n",
    "\n",
    "data = {\n",
    "        \"dbName\": MDB_DATABASE,\n",
    "        \"collName\": MDB_COLLECTION,\n",
    "        \"partitionFields\": [\n",
    "              {\n",
    "                      \"fieldType\": \"string\",\n",
    "                      \"fieldName\": \"userName\",\n",
    "                      \"order\": 0\n",
    "              }],    \n",
    "        \"criteria\": {\n",
    "              \"dateField\": date_field,\n",
    "              \"expireAfterDays\": 30\n",
    "          }\n",
    "}\n",
    "headers = {\"content-type\":\"application/json\"}\n",
    "    \n",
    "resp = requests.post(url, auth=HTTPDigestAuth(API_PUBLIC_KEY, API_PRIVATE_KEY), json=data, headers=headers)\n",
    "\n",
    "if resp.ok:\n",
    "    \n",
    "    print(\"Archive Created\")\n",
    "    print(resp.json())\n",
    "    \n",
    "else:\n",
    "   print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE\n"
     ]
    }
   ],
   "source": [
    "# Wait for archive to become active\n",
    "archive_id = get_archive_id()\n",
    "\n",
    "state = get_archive_state(archive_id) \n",
    "if (state == 'ACTIVE'):\n",
    "    print(state)\n",
    "else:\n",
    "    print (\"Waiting for archive to build\")\n",
    "\n",
    "while state != 'ACTIVE':\n",
    "    state = get_archive_state(archive_id) \n",
    "    print(\".\", end=\"\")    \n",
    "    if (state == 'ACTIVE'):\n",
    "        print (\"\\n\" + state)\n",
    "        break;\n",
    "    else:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Generation\n",
    "This script uses [Faker](https://faker.readthedocs.io/en/master/) to randomly generate 1000 IoT events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "   Generating Sample IoT Data   \n",
      "================================\n",
      "\n",
      "Starting 2020-07-14 22:00:03\n",
      "\n",
      "NUM DOCS TO GENERATE: 1000\n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Ending 2020-07-14 22:00:45\n",
      "===============================\n",
      "Total Time Elapsed (in seconds): 41.68088469599934\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# Start script\n",
    "startTs = time.gmtime()\n",
    "start = timer()\n",
    "print(\"================================\")\n",
    "print(\"   Generating Sample IoT Data   \")\n",
    "print(\"================================\")\n",
    "print(\"\\nStarting \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", startTs) + \"\\n\")\n",
    "\n",
    "print('NUM DOCS TO GENERATE: ' + str(NUM_DOCS))\n",
    "\n",
    "mongo_client = MongoClient(MDB_CONNECTION)\n",
    "db = mongo_client[MDB_DATABASE]\n",
    "my_collection = db[MDB_COLLECTION]\n",
    "\n",
    "# Remove the existing documents (don't drop the collection from underneath the archive)\n",
    "my_collection.delete_many({})\n",
    "\n",
    "for index in range(int(NUM_DOCS)):\n",
    "    # create timestamp\n",
    "    fake_timestamp = fake.date_this_year()\n",
    "\n",
    "    # Define IoT Document\n",
    "    my_iot_document = {\n",
    "        \"username\": fake.user_name(),\n",
    "        \"remote_ipv4\": fake.ipv4(),\n",
    "        \"httpMethod\": fake.http_method(),\n",
    "        \"hostName\": fake.hostname(),\n",
    "        \"portNum\": fake.port_number(),\n",
    "        \"location\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [\n",
    "                    Decimal128(fake.longitude()),\n",
    "                    Decimal128(fake.latitude())\n",
    "                ]\n",
    "        },\n",
    "        \"dateAccessed\": datetime.datetime(fake_timestamp.year, fake_timestamp.month, fake_timestamp.day)\n",
    "    }\n",
    "    # print(my_iot_document)\n",
    "    print(\".\", end=\"\")\n",
    "    my_collection.insert_one(my_iot_document)\n",
    "\n",
    "# Indicate end of script\n",
    "end = timer()\n",
    "endTs = time.gmtime()\n",
    "print(\"\\nEnding \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", endTs))\n",
    "print('===============================')\n",
    "print('Total Time Elapsed (in seconds): ' + str(end - start))\n",
    "print('===============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Query\n",
    "While IoT events are generating, query the cluster's document count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive has begun:\n",
      "   158      Total number of documents in the Atlas Cluster\n"
     ]
    }
   ],
   "source": [
    "mongo_client = MongoClient(MDB_CONNECTION)\n",
    "db = mongo_client[MDB_DATABASE]\n",
    "my_collection = db[MDB_COLLECTION]\n",
    "\n",
    "cluster_count = my_collection.count_documents({})\n",
    "\n",
    "while count == 1000:\n",
    "    print (\"Waiting for documents to archive\")\n",
    "    print(\".\", end=\"\")\n",
    "\n",
    "print(\"Archive has begun:\")\n",
    "cluster_count = my_collection.count_documents({})\n",
    "print_row (count, \"Total number of documents in the Atlas Cluster\")\n",
    "\n",
    "# While the document count is shrinking\n",
    "while my_collection.count_documents({}) < cluster_count:\n",
    "    print_row (count, \"Total number of documents in the Atlas Cluster\")\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster and Online Archive\n",
    "\n",
    "While the Atlas Cluster has some subset of the documents, there are still 1000 documents across the cluster and archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive date (30 days ago): 2020-06-14\n",
      "\n",
      "   156      Total number of documents in the Atlas Cluster\n",
      "     0      Total number of documents in the Atlas Cluster older than 30 days\n",
      "  1686      Total number of documents across the Atlas Cluster and the Online Archive older than 30 days\n",
      "------\n",
      "  1842      Total number of documents across the Atlas Cluster and Online Archive\n"
     ]
    }
   ],
   "source": [
    "# Establish a connection to the Cluster and Online Archive\n",
    "mongo_client_archive = MongoClient(MDB_CONNECTION_ARCHIVE)\n",
    "archive_db = mongo_client_archive[MDB_DATABASE]\n",
    "my_collection_archive = archive_db[MDB_COLLECTION]\n",
    "\n",
    "cluster_count = my_collection.count_documents({'dateAccessed':{'$lt': archive_date}})\n",
    "cluster_archive_count = my_collection_archive.count_documents({'dateAccessed':{'$lt': archive_date}})\n",
    "\n",
    "print(\"Archive date (30 days ago): \" + str(archive_date.date()))\n",
    "print('')\n",
    "print_row(my_collection.count_documents({}), \"Total number of documents in the Atlas Cluster\")\n",
    "print_row(cluster_count, \"Total number of documents in the Atlas Cluster older than 30 days\")\n",
    "print_row(cluster_archive_count, \"Total number of documents across the Atlas Cluster and the Online Archive older than 30 days\")\n",
    "print('------')\n",
    "print_row(my_collection_archive.count_documents({}), \"Total number of documents across the Atlas Cluster and Online Archive\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
